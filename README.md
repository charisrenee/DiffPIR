# Leveraging Diffusion Models For Predominant Instrument Recognition

## Audio examples are avaiable [here](https://bit.ly/DiffPIR-SoundExamples).

*Full Update Coming Soon!

This repo contains the code for the experiments and dataset accompanying the [AI for Music Workshop](https://aiformusicworkshop.github.io/ "AI for Music Workshop") at NEURIPS 2025  paper "Leveraging Diffusion Models For Predominant Instrument Recognition" presented investigating the utility of features froma  pretrained diffusion model for the downstream task of PIR.

The OpenPIR metatdata contains filepaths and samplekeys corresponding to samples from [OpenMic-2018](https://github.com/cosmir/openmic-2018/tree/master), as well as instrument, genre, and drums labels corresponding to the [IRMAS](https://www.upf.edu/web/mtg/irmas) taxonamy of predominant instruments and genre subset.

