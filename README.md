# Leveraging Diffusion Models For Predominant Instrument Recognition

## This repo is being revised January 2026 to reflect the ICASSP 2026 paper corresponding to this work. ##

* Below is the NeurIPS workshop paper information.

## Audio examples are avaiable [here](https://bit.ly/DiffPIR-SoundExamples).

This repo contains the code for the experiments and dataset accompanying the [AI for Music Workshop](https://aiformusicworkshop.github.io/ "AI for Music Workshop") at NEURIPS 2025  paper "Leveraging Diffusion Models For Predominant Instrument Recognition" presented investigating the utility of features from a  pretrained diffusion model for the downstream task of PIR.

The OpenPIR metatdata contains filepaths and samplekeys corresponding to samples from [OpenMic-2018](https://github.com/cosmir/openmic-2018/tree/master), as well as instrument, genre, and drums labels corresponding to the [IRMAS](https://www.upf.edu/web/mtg/irmas) taxonamy of predominant instruments and genre subset.

